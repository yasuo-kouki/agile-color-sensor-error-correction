\section{考察}
\subsection{MSEとモデルサイズの関係}

本実験では，ベースラインモデルおよび Sparse + CSR + int8 モデルのいずれにおいても，
パラメータ数やモデルサイズと MSE の間に明確な相関関係は見られなかった（図5，図8，図10）．
ベースラインモデルでは，パラメータ数 30～60 に対して 
MSE の平均値は約 250～450 の範囲でばらついており，
パラメータ数 50 のときに最小 MSE（約 249）が得られている一方で，
それより大きなパラメータ数 60 では MSE が再び増加している．
同様に，Sparse + CSR + int8 モデルでも，パラメータ数を 30 から 1100 まで大きく変化させても 
MSE は 200～500 程度の範囲に散らばっており，モデルサイズの増加が必ずしも MSE の改善にはつながっていない．

この結果は，本研究で扱ったカラーセンサー補正タスクが比較的単純であり，
小さなモデルでも必要な表現能力をすでに満たしている可能性を示唆している．
すなわち，一定以上パラメータ数を増やしても表現能力の上限に達しており，
モデルの自由度の増加が MSE の低減として現れなかったと解釈できる．
加えて，学習データ数に対してパラメータ数が大きくなり過ぎると，
学習過程での初期値や最適化経路の違いによるばらつきや，軽度の過学習の影響が MSE に表れている可能性もある．

また，量子化およびスパース化を施したモデルでは，重みが int8 に丸められ，
一部の小さな重みが 0 に置き換えられているにもかかわらず，
MSE が大きく悪化していない点も考察する．
これは，本タスクでは高精度の浮動小数点表現が必須ではなく，
8 ビット整数および疎構造に変換しても，
色補正の性能には大きな影響を与えないことを意味している．
一部の条件ではむしろ圧縮モデルの MSE がベースラインと同等かそれ以下になっており，
量子化やスパース化による「ゆるい正則化効果」が過学習の抑制に寄与した可能性も考えられる\cite{toshiba2019}．

\subsection{削減率の挙動に関する考察}

本実験では，モデルサイズの評価指標として「削減率」を用い，これは以下のように定義される．
\[
  \mathrm{削減率}
  = 1 - \frac{S_{\mathrm{comp}}}{S_{\mathrm{orig}}}
\]

そのため，表\ref{tab:csr_int8_results} における 0.8561 や 0.9994 といった値は，
「元のモデルサイズから何割削減できたか」を表している．

Sparse + CSR + int8 モデルでは，パラメータ数 30 のときの削減率は約 85.6\% であり，
元のモデルの約 8 程度の容量にまで削減できている．パラメータ数を増やしていくと削減率はさらに増加し，
パラメータ数 200 以上では 99\% を超え，1100 では約 99.94\% に達している．
これは，ベースラインモデルのサイズがパラメータ数にほぼ比例して増加する一方で，
圧縮後のモデルサイズはパラメータ数に対して緩やかにしか増加していないことを意味する．

この挙動の背景には，以下の 2 点があると考えられる．
1つ目は，スパース化により多くの重みが 0 に置き換えられていることである．
パラメータ数を増やすほど，学習後に実質的に寄与しない小さな重みも増加しやすく，閾値以下の要素が大量に 0 となる\cite{toshiba2019}．
その結果，CSR 形式で保持すべき非ゼロ要素の個数はパラメータ数ほどは増えず，容量の増加が抑制される．
2つ目は，量子化による 1 要素あたりの表現ビット数の削減である．
ベースラインでは float32（4 バイト）で重みを表現しているのに対し，
圧縮モデルでは int8（1 バイト）を用いており，
非ゼロ要素に対しては理論上 1/4 まで縮小できる．
これに CSR 形式による疎構造の活用が加わることで，総体として 1\% 以下まで容量を抑えられている．

スパース化のみを適用した表\ref{h_results} では，閾値 (\alpha) を 0.05 から 0.005 に変化させても削減率は 0.54 台からほとんど変化していない．
これは，元の重み分布において (|w| < 0.005) のような「非常に小さい値」がそもそも少なく，
0.005 以下の範囲で閾値を変えても 0 になる要素の数が大きく変化しなかった可能性を示唆している．
つまり，学習済みモデルはもともとある程度スパースな性質を持っており，
今回の閾値設定の範囲では削減効果に大きな差が出なかったと考えられる．

\subsection{モデルサイズと推論時間の関係}

図\ref{fig:time_tradeoff}に示されるように，
ベースラインモデルではモデルサイズの増加に伴い推論時間も増加しており，
両者の間に正の相関傾向が確認できる． 
これは，全結合層の計算量がパラメータ数にほぼ比例するためであり，
より大きなモデルほど行列積演算の回数が増え，推論時間が長くなることを反映している\cite{ngo2025}．

また，Sparse + CSR + int8 モデルにおいても，パラメータ数が大きくなるほど推論時間が増加する傾向が見らた．
CSR や int8 から浮動小数点への復元が推論時に必要となるためベースラインモデルよりも推論時間が増加している．

このことから，圧縮モデルはサイズ削減によるメモリ効率の利点を持つ一方で，
推論処理においては復元処理が無視できない時間コストとなり，
その分だけベースラインモデルより遅くなるケースが存在する．
これは，組み込みデバイス上で圧縮モデルを運用する際に，
メモリ削減と計算コストの両面から最適な圧縮パラメータを選択する必要があることを示唆している．

\subsection{圧縮モデルとベースラインモデルの比較}

同一パラメータ数におけるベースラインモデルと Sparse + CSR + int8 モデルの比較（表4, 図9）からは，
圧縮によってモデルサイズを大幅に削減しつつ，
MSE をほぼ維持できていることが確認できる．
 例えば param = 30 では，ベースラインの MSE が 417.726 に対して圧縮モデルは 379.674 であり，
 MSE をほとんど悪化させることなく容量を約 85\% 削減できている．param = 40 と 60 でも，
 両モデルの MSE は同程度であり，いずれも圧縮による精度劣化は限定的である．

一方で，param = 50 では圧縮モデルの MSE がベースラインよりも大きくなっており，
圧縮処理による情報損失の影響が現れた例と考えられる．
ただし，各条件で MSE は 5 回測定の平均値であり，ばらつきも存在することから，
単一条件の逆転のみで圧縮手法の有効性を否定することはできない．
全体として見れば多くの条件で容量は削減しながら，
MSE は同程度または許容範囲内の増加に収まっていると評価できる．

さらに，param = 70 に関しては，ベースラインモデルはモデルサイズが大きく測定不能であった一方，
Sparse + CSR + int8 モデルでは約 3KB まで圧縮され，
しかも MSE は 216.734 と，本実験中でも最小クラスの値を示した．
これは，圧縮技術を用いることで，ベースラインでは実装困難であったパラメータ数のモデルを，
実用的なサイズで扱えるようになることを示している．
メモリ制約の厳しい Arduino R4 WiFi のような環境では，
大きなモデルを圧縮して載せる戦略が特に有効であると考えられる．


